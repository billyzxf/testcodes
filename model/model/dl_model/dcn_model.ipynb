{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42f28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474afddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['phone_model', 'browser_family', 'os_family', 'device_brand', 'city_code', 'province_code',\n",
    "                        'sex', 'hashouse', 'social', 'overdue',\n",
    "                        'tax', 'married', 'benke', 'kid', 'income', 'consumption', 'shebao']\n",
    "\n",
    "text_features = ['clicked_products_0009', 'clicked_products_date_0009', 'sms_sent_products_0009',\n",
    "                 'sms_sent_products_1019', 'sms_sent_products_date_0009', 'sms_sent_products_date_1019',\n",
    "                 'called_products_0009', 'called_products_1019', 'called_products_date_0009',\n",
    "                 'called_products_date_1019', 'picked_products_0009', 'picked_products_date_0009',\n",
    "                 'outbound_sent_products_0009', 'outbound_sent_products_date_0009', 'set_all_ins_host_180', 'set_all_ins_host_360',] \\\n",
    "                + ['keypress_30', 'keypress_60', 'keypress_90', 'keypress_120',\n",
    "                   'rule_name_30', 'rule_name_60', 'rule_name_90', 'rule_name_120',\n",
    "                   'semantic_30', 'semantic_60', 'semantic_90', 'semantic_120', 'model_value']\n",
    "\n",
    "text_feature_types = ['products', 'keypress', 'rules', 'semantics', 'insurances', 'model_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28fe500",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"../../data/train_data_ifh4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb51ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[text_features] = train_df[text_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1ce86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_model</th>\n",
       "      <th>browser_family</th>\n",
       "      <th>os_family</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>city_code</th>\n",
       "      <th>province_code</th>\n",
       "      <th>sex</th>\n",
       "      <th>hashouse</th>\n",
       "      <th>social</th>\n",
       "      <th>overdue</th>\n",
       "      <th>tax</th>\n",
       "      <th>married</th>\n",
       "      <th>benke</th>\n",
       "      <th>kid</th>\n",
       "      <th>income</th>\n",
       "      <th>consumption</th>\n",
       "      <th>shebao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phone_model  browser_family  os_family  device_brand  city_code  \\\n",
       "0            2               0          1             0         24   \n",
       "1            2               1          0             1         28   \n",
       "2            3               0          1             0         15   \n",
       "3           10               1          0             1        103   \n",
       "4            5               0          1             0          1   \n",
       "\n",
       "   province_code  sex  hashouse  social  overdue  tax  married  benke  kid  \\\n",
       "0              5    2         0       1        0    0        0      0    0   \n",
       "1              2    1         0       0        0    0        0      0    0   \n",
       "2              3    1         0       0        0    0        0      1    0   \n",
       "3              5    1         0       0        0    0        0      1    0   \n",
       "4              0    2         0       0        0    0        0      0    0   \n",
       "\n",
       "   income  consumption  shebao  \n",
       "0       0            0       0  \n",
       "1       0            0       0  \n",
       "2       0            0       0  \n",
       "3       0            0       0  \n",
       "4       0            0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[categorical_features].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa76d9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clicked_products_0009</th>\n",
       "      <th>clicked_products_date_0009</th>\n",
       "      <th>sms_sent_products_0009</th>\n",
       "      <th>sms_sent_products_1019</th>\n",
       "      <th>sms_sent_products_date_0009</th>\n",
       "      <th>sms_sent_products_date_1019</th>\n",
       "      <th>called_products_0009</th>\n",
       "      <th>called_products_1019</th>\n",
       "      <th>called_products_date_0009</th>\n",
       "      <th>called_products_date_1019</th>\n",
       "      <th>...</th>\n",
       "      <th>keypress_120</th>\n",
       "      <th>rule_name_30</th>\n",
       "      <th>rule_name_60</th>\n",
       "      <th>rule_name_90</th>\n",
       "      <th>rule_name_120</th>\n",
       "      <th>semantic_30</th>\n",
       "      <th>semantic_60</th>\n",
       "      <th>semantic_90</th>\n",
       "      <th>semantic_120</th>\n",
       "      <th>model_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>小助理 运营商提示音</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>baotai27_其他</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>144 145 140 143</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>IYBPAZX_ZTKMF_OPPOJX_BT IYBPAZX_ZTKMF_OPPOJX_BT</td>\n",
       "      <td>nan</td>\n",
       "      <td>2D 4D</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>baotai27_G</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7 9 140 150 151 7 131 131</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FQL IYBPAZX_ZMF_CS_BT NWZAZX_ZNWZAMF_NEWOPPO_B...</td>\n",
       "      <td>12D 12D 15D 24D 30D 32D 36D 38D 41D 44D</td>\n",
       "      <td>IYBPAZX_ZTKMF_OPPOJX_BT NWZAZX_ZNWZAMF_NEWOPPO...</td>\n",
       "      <td>IYBPAZX_ZTKMF_OPPOJX_BT IYBPAZX_ZMF_CS_BT IYBP...</td>\n",
       "      <td>2D 4D 8D 10D 12D 15D 20D 24D 26D 28D</td>\n",
       "      <td>30D 32D 34D 36D 39D 43D 45D 47D 51D 53D</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>触发发短信 sendMessage_special 没输入手机号 输入手机号2 输入手机号3...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>yingdian888_B jiyonghua661_B huirong888_D ying...</td>\n",
       "      <td>mayi02_D baotai14_B mayi02_D mayi02_D</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2240 2572 2672 2313 2345 2672 2313 2313 2313 2...</td>\n",
       "      <td>23 24 46 3921 35 21 21 2576 2181 2189 24 23 23...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>IYBPAZX_ZTKMF_OPPOJX_BT IYBPAZX_ZMF_CS_BT IYBP...</td>\n",
       "      <td>nan</td>\n",
       "      <td>2D 4D 6D</td>\n",
       "      <td>nan</td>\n",
       "      <td>IYBPAZX_TKMF_GD_BZ_GZH_WH IYBPAZX_TKMF_GD_BZ_G...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1D 4D 7D 52D 55D 58D</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>触发发短信 sendMessage_special</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>baotai27_D</td>\n",
       "      <td>baotai27_其他</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               clicked_products_0009  \\\n",
       "0                                                nan   \n",
       "1                                                nan   \n",
       "2                                                nan   \n",
       "3  FQL IYBPAZX_ZMF_CS_BT NWZAZX_ZNWZAMF_NEWOPPO_B...   \n",
       "4                                                nan   \n",
       "\n",
       "                clicked_products_date_0009  \\\n",
       "0                                      nan   \n",
       "1                                      nan   \n",
       "2                                      nan   \n",
       "3  12D 12D 15D 24D 30D 32D 36D 38D 41D 44D   \n",
       "4                                      nan   \n",
       "\n",
       "                              sms_sent_products_0009  \\\n",
       "0                                                nan   \n",
       "1    IYBPAZX_ZTKMF_OPPOJX_BT IYBPAZX_ZTKMF_OPPOJX_BT   \n",
       "2                                                nan   \n",
       "3  IYBPAZX_ZTKMF_OPPOJX_BT NWZAZX_ZNWZAMF_NEWOPPO...   \n",
       "4  IYBPAZX_ZTKMF_OPPOJX_BT IYBPAZX_ZMF_CS_BT IYBP...   \n",
       "\n",
       "                              sms_sent_products_1019  \\\n",
       "0                                                nan   \n",
       "1                                                nan   \n",
       "2                                                nan   \n",
       "3  IYBPAZX_ZTKMF_OPPOJX_BT IYBPAZX_ZMF_CS_BT IYBP...   \n",
       "4                                                nan   \n",
       "\n",
       "            sms_sent_products_date_0009  \\\n",
       "0                                   nan   \n",
       "1                                 2D 4D   \n",
       "2                                   nan   \n",
       "3  2D 4D 8D 10D 12D 15D 20D 24D 26D 28D   \n",
       "4                              2D 4D 6D   \n",
       "\n",
       "               sms_sent_products_date_1019  \\\n",
       "0                                      nan   \n",
       "1                                      nan   \n",
       "2                                      nan   \n",
       "3  30D 32D 34D 36D 39D 43D 45D 47D 51D 53D   \n",
       "4                                      nan   \n",
       "\n",
       "                                called_products_0009 called_products_1019  \\\n",
       "0                                                nan                  nan   \n",
       "1                                                nan                  nan   \n",
       "2                                                nan                  nan   \n",
       "3                                                nan                  nan   \n",
       "4  IYBPAZX_TKMF_GD_BZ_GZH_WH IYBPAZX_TKMF_GD_BZ_G...                  nan   \n",
       "\n",
       "  called_products_date_0009 called_products_date_1019  ...  \\\n",
       "0                       nan                       nan  ...   \n",
       "1                       nan                       nan  ...   \n",
       "2                       nan                       nan  ...   \n",
       "3                       nan                       nan  ...   \n",
       "4      1D 4D 7D 52D 55D 58D                       nan  ...   \n",
       "\n",
       "                                        keypress_120 rule_name_30  \\\n",
       "0                                         小助理 运营商提示音          nan   \n",
       "1                                                nan          nan   \n",
       "2                                                nan          nan   \n",
       "3  触发发短信 sendMessage_special 没输入手机号 输入手机号2 输入手机号3...          nan   \n",
       "4                          触发发短信 sendMessage_special          nan   \n",
       "\n",
       "  rule_name_60                                       rule_name_90  \\\n",
       "0          nan                                                nan   \n",
       "1          nan                                                nan   \n",
       "2          nan                                         baotai27_G   \n",
       "3          nan  yingdian888_B jiyonghua661_B huirong888_D ying...   \n",
       "4          nan                                         baotai27_D   \n",
       "\n",
       "                           rule_name_120 semantic_30 semantic_60  \\\n",
       "0                            baotai27_其他         nan         nan   \n",
       "1                                    nan         nan         nan   \n",
       "2                                    nan         nan         nan   \n",
       "3  mayi02_D baotai14_B mayi02_D mayi02_D         nan         nan   \n",
       "4                            baotai27_其他         nan         nan   \n",
       "\n",
       "                                         semantic_90  \\\n",
       "0                                                nan   \n",
       "1                                                nan   \n",
       "2                          7 9 140 150 151 7 131 131   \n",
       "3  2240 2572 2672 2313 2345 2672 2313 2313 2313 2...   \n",
       "4                                                nan   \n",
       "\n",
       "                                        semantic_120 model_value  \n",
       "0                                    144 145 140 143         nan  \n",
       "1                                                nan         nan  \n",
       "2                                                nan         nan  \n",
       "3  23 24 46 3921 35 21 21 2576 2181 2189 24 23 23...         nan  \n",
       "4                                                nan         nan  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[text_features].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b3a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(feature_type):\n",
    "    words = train_df[feature_type].dropna().str.split(' ')\n",
    "    exploded_words = words.explode()\n",
    "    vocabulary = exploded_words.value_counts()\n",
    "    vocabulary = vocabulary[vocabulary > 5]\n",
    "    vocab_size = vocabulary.shape[0]\n",
    "    vocabulary = vocabulary.index.tolist()\n",
    "\n",
    "    return vocabulary, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b542d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {}\n",
    "for type in text_feature_types:\n",
    "    vocab_dict[type] = get_vocabulary(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99e7e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_dict = {col: vocab_info[1]+100 for col, vocab_info in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9818728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'products': 273,\n",
       " 'keypress': 207,\n",
       " 'rules': 328,\n",
       " 'semantics': 351,\n",
       " 'insurances': 141,\n",
       " 'model_value': 102}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd701547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../../data/dicts/token_dict.pkl', 'rb') as f:\n",
    "    token_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e60349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_dict = {\n",
    "    'called_products_0009': 10,\n",
    "    'called_products_1019': 6,\n",
    "    'called_products_date_0009': 10,\n",
    "    'called_products_date_1019': 6,\n",
    "    'clicked_products_0009': 3,\n",
    "    'clicked_products_date_0009': 3,\n",
    "    'keypress_120': 3,\n",
    "    'keypress_30': 3,\n",
    "    'keypress_60': 3,\n",
    "    'keypress_90': 3,\n",
    "    'label_0009': 3,\n",
    "    'label_1019': 3,\n",
    "    'label_date_0009': 3,\n",
    "    'label_date_1019': 3,\n",
    "    'model_value': 3,\n",
    "    'outbound_sent_products_0009': 3,\n",
    "    'outbound_sent_products_date_0009': 3,\n",
    "    'picked_products_0009': 3,\n",
    "    'picked_products_date_0009': 3,\n",
    "    'rule_name_120': 3,\n",
    "    'rule_name_30': 3,\n",
    "    'rule_name_60': 3,\n",
    "    'rule_name_90': 3,\n",
    "    'semantic_120': 5,\n",
    "    'semantic_30': 3,\n",
    "    'semantic_60': 3,\n",
    "    'semantic_90': 5,\n",
    "    'set_all_ins_host_180': 5,\n",
    "    'set_all_ins_host_360': 4,\n",
    "    'sms_sent_products_0009': 10,\n",
    "    'sms_sent_products_1019': 9,\n",
    "    'sms_sent_products_date_0009': 10,\n",
    "    'sms_sent_products_date_1019': 9\n",
    " }\n",
    "\n",
    "category_counts_dict = {col: train_df[col].nunique() for col in categorical_features}\n",
    "\n",
    "\n",
    "def get_text_feature_type(col):\n",
    "    if 'set_' in col:\n",
    "        text_feature_type = 'insurances'\n",
    "    elif 'host_' in col:\n",
    "        text_feature_type = 'hosts'\n",
    "    elif 'products_' in col:\n",
    "        text_feature_type = 'products'\n",
    "    elif 'label_' in col:\n",
    "        text_feature_type = 'labels'\n",
    "    elif 'keypress_' in col:\n",
    "        text_feature_type = 'keypress'\n",
    "    elif 'rule_name_' in col:\n",
    "        text_feature_type = 'rules'\n",
    "    elif 'semantic_' in col:\n",
    "        text_feature_type = 'semantics'\n",
    "    else:\n",
    "        text_feature_type = 'model_value'\n",
    "    return text_feature_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77afc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore numerical features\n",
    "restored_raw = (\n",
    "    train_df[\"numerical_features\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"\\n\", \" \", regex=False)\n",
    "    .str.strip(\"[]\")\n",
    "    .str.strip()\n",
    "    .str.split(r\"\\s+\", expand=True)\n",
    "    .apply(lambda col: pd.to_numeric(col.replace('', pd.NA), errors='coerce'))\n",
    "    .fillna(0)\n",
    "    .to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "131b7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_train_cro = train_df['label'].str.strip(\"[]\").str.split(\" \", expand=True).astype(int).to_numpy()\n",
    "\n",
    "# X\n",
    "X_train = {'numerical_features': restored_raw}\n",
    "\n",
    "for col in categorical_features:\n",
    "    X_train[col] = np.array(train_df[col])\n",
    "\n",
    "for col in text_features:\n",
    "    with open(f'../../data/text_features/{col}.pkl', 'rb') as f:\n",
    "        X_train[col] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6bb553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 拆分索引\n",
    "indices = np.arange(len(y_train_cro))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=y_train_cro)\n",
    "\n",
    "# 拆分 y\n",
    "y_train_split = y_train_cro[train_idx]\n",
    "y_test_split = y_train_cro[test_idx]\n",
    "\n",
    "# 拆分 X\n",
    "X_train_split = {}\n",
    "X_test_split = {}\n",
    "for key in X_train:\n",
    "    arr = X_train[key]\n",
    "    X_train_split[key] = arr[train_idx]\n",
    "    X_test_split[key] = arr[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4fb5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Deep Cross Network layer (DCN).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers=3, *args, **kwargs):\n",
    "        super(CrossLayer, self).__init__(**kwargs)\n",
    "        # 如果第一个位置参数传入的是类似 CrossLayer(1, ...)，则 num_layers==1，其他位置参数被忽略\n",
    "        self.num_layers = int(num_layers)\n",
    "        self.input_spec = tf.keras.layers.InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        self.input_dim = int(input_shape[1])\n",
    "        # 每层使用向量 w (shape = (input_dim, 1)) 和偏置 b (shape = (input_dim,))\n",
    "        self.kernels = []\n",
    "        self.biases = []\n",
    "        for i in range(self.num_layers):\n",
    "            self.kernels.append(\n",
    "                self.add_weight(name=f'cross_w_{i}', shape=(self.input_dim, 1),\n",
    "                                initializer='glorot_uniform', trainable=True)\n",
    "            )\n",
    "            self.biases.append(\n",
    "                self.add_weight(name=f'cross_b_{i}', shape=(self.input_dim,),\n",
    "                                initializer='zeros', trainable=True)\n",
    "            )\n",
    "        super(CrossLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs: (batch, input_dim)\n",
    "        x0 = tf.cast(inputs, tf.float32)\n",
    "        xl = x0\n",
    "        for i in range(self.num_layers):\n",
    "            # dot = (batch,1) := xl @ w_i\n",
    "            dot = tf.matmul(xl, self.kernels[i])  # (batch,1)\n",
    "            # cross = x0 * dot  -> broadcasting to (batch, input_dim)\n",
    "            cross = x0 * dot  # broadcast multiplication\n",
    "            # xl_next = cross + b + xl\n",
    "            xl = cross + self.biases[i] + xl\n",
    "        return xl  # (batch, input_dim)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CrossLayer, self).get_config()\n",
    "        config.update({'num_layers': self.num_layers})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0a68bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_model(output_units=1, dnn_hidden_units=[1024, 512, 256], \n",
    "                dropout_rate_dnn_input=0.1, dropout_rate_dnn_logit=0.1, l2_reg_dnn=0.0,\n",
    "                dropout_rate_cross_input=0.1, dropout_rate_cross_logit=0.1, \n",
    "                l2_reg_text_embedding=0.0, l2_reg_categorical_embedding=0.0):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # text inputs\n",
    "    text_inputs = [tf.keras.layers.Input(shape=(max_len_dict[col],), name=col) for col in text_features]\n",
    "    text_embeddings = []\n",
    "    for i, col in enumerate(text_features):\n",
    "        text_feature_type = get_text_feature_type(col)\n",
    "        text_embeddings.append(\n",
    "            tf.keras.layers.Embedding(vocab_size_dict[text_feature_type]+2,\n",
    "                                      int(np.log1p(vocab_size_dict[text_feature_type]) + 2),\n",
    "                                      embeddings_regularizer=tf.keras.regularizers.l2(l2_reg_text_embedding),\n",
    "                                      name=col + '_embed')(text_inputs[i])\n",
    "        )\n",
    "        \n",
    "    text_logit = tf.keras.layers.Concatenate(name='text_concat')(\n",
    "        [tf.keras.layers.GlobalAveragePooling1D()(text_emb) for text_emb in text_embeddings]\n",
    "    )\n",
    "\n",
    "    # categorical inputs\n",
    "    categorical_inputs = [tf.keras.layers.Input(shape=(1,), name=col) for col in categorical_features]\n",
    "    categorical_embeddings = []\n",
    "    for i, col in enumerate(categorical_features):\n",
    "        categorical_embeddings.append(\n",
    "            tf.keras.layers.Embedding(category_counts_dict[col]+2, int(np.log1p(category_counts_dict[col]) + 2),\n",
    "                                      embeddings_regularizer=tf.keras.regularizers.l2(l2_reg_categorical_embedding),\n",
    "                                      name=col + '_embed')(categorical_inputs[i])\n",
    "        )\n",
    "\n",
    "    categorical_logit = tf.keras.layers.Concatenate(name='categorical_concat')(\n",
    "        [tf.keras.layers.Flatten()(cat_emb) for cat_emb in categorical_embeddings]\n",
    "    )\n",
    "\n",
    "    # numerical inputs\n",
    "    numerical_input = tf.keras.layers.Input(shape=(230,), name='numerical_features')\n",
    "\n",
    "    # dnn\n",
    "    dnn_input = tf.keras.layers.Concatenate(name='deep_concat')([text_logit, categorical_logit, numerical_input])\n",
    "    dnn_logit = tf.keras.layers.Dropout(dropout_rate_dnn_input)(dnn_input)\n",
    "    for n_unit in dnn_hidden_units:\n",
    "        dnn_logit = tf.keras.layers.Dense(n_unit, activation='relu',\n",
    "                                          kernel_regularizer=tf.keras.regularizers.l2(l2_reg_dnn))(dnn_logit)\n",
    "        dnn_logit = tf.keras.layers.Dropout(dropout_rate_dnn_logit)(dnn_logit)\n",
    "\n",
    "    # cross\n",
    "    cross_input = tf.keras.layers.Concatenate(name='cross_concat')([text_logit, categorical_logit, numerical_input])\n",
    "    cross_logit = tf.keras.layers.Dropout(dropout_rate_cross_input)(cross_input)\n",
    "    cross_logit = CrossLayer(num_layers=3)(cross_logit)\n",
    "    cross_logit = tf.keras.layers.Dropout(dropout_rate_cross_logit)(cross_logit)\n",
    "\n",
    "    outputs = tf.keras.layers.Concatenate()([dnn_logit, cross_logit])\n",
    "    outputs = tf.keras.layers.Dense(output_units, activation='sigmoid')(outputs)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=text_inputs + categorical_inputs + [numerical_input], outputs=outputs, name='DeepCross')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc2dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "n_epochs = 100\n",
    "batch_size = 1024\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=1, min_lr=0.00005, verbose=1)\n",
    "callbacks = [es, reduce_lr]\n",
    "\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test):\n",
    "    output_units = 3\n",
    "    model = cross_model(output_units)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy(name='acc'), tf.keras.metrics.AUC(name='auc')],\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr))\n",
    "    \n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
    "              epochs=n_epochs, batch_size=batch_size, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f28d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DT-Liuxiangfei\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 494ms/step - acc: 0.7517 - auc: 0.7334 - loss: 2.6554 - val_acc: 0.8508 - val_auc: 0.8225 - val_loss: 1.4131 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - acc: 0.8761 - auc: 0.8547 - loss: 2.4483 - val_acc: 0.9049 - val_auc: 0.8814 - val_loss: 1.1644 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - acc: 0.9117 - auc: 0.8932 - loss: 2.2393 - val_acc: 0.9269 - val_auc: 0.9022 - val_loss: 0.9762 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - acc: 0.9298 - auc: 0.9127 - loss: 1.4515 - val_acc: 0.9367 - val_auc: 0.9182 - val_loss: 0.8604 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - acc: 0.9373 - auc: 0.9219 - loss: 1.7660 - val_acc: 0.9406 - val_auc: 0.9277 - val_loss: 0.7918 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - acc: 0.9413 - auc: 0.9297 - loss: 1.2899 - val_acc: 0.9437 - val_auc: 0.9340 - val_loss: 0.7458 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - acc: 0.9440 - auc: 0.9376 - loss: 1.5409 - val_acc: 0.9452 - val_auc: 0.9380 - val_loss: 0.7115 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - acc: 0.9441 - auc: 0.9391 - loss: 1.4546 - val_acc: 0.9459 - val_auc: 0.9404 - val_loss: 0.6831 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - acc: 0.9456 - auc: 0.9420 - loss: 1.3593 - val_acc: 0.9464 - val_auc: 0.9421 - val_loss: 0.6604 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - acc: 0.9445 - auc: 0.9427 - loss: 0.9356 - val_acc: 0.9469 - val_auc: 0.9435 - val_loss: 0.6365 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - acc: 0.9461 - auc: 0.9439 - loss: 1.2472 - val_acc: 0.9475 - val_auc: 0.9446 - val_loss: 0.6128 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - acc: 0.9463 - auc: 0.9450 - loss: 1.1494 - val_acc: 0.9474 - val_auc: 0.9463 - val_loss: 0.5942 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - acc: 0.9457 - auc: 0.9451 - loss: 0.9345 - val_acc: 0.9481 - val_auc: 0.9483 - val_loss: 0.5779 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - acc: 0.9465 - auc: 0.9475 - loss: 0.8286 - val_acc: 0.9489 - val_auc: 0.9490 - val_loss: 0.5640 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - acc: 0.9471 - auc: 0.9484 - loss: 0.7690 - val_acc: 0.9492 - val_auc: 0.9499 - val_loss: 0.5501 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - acc: 0.9475 - auc: 0.9492 - loss: 0.6933 - val_acc: 0.9487 - val_auc: 0.9508 - val_loss: 0.5361 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - acc: 0.9471 - auc: 0.9506 - loss: 0.9820 - val_acc: 0.9492 - val_auc: 0.9519 - val_loss: 0.5239 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - acc: 0.9472 - auc: 0.9503 - loss: 1.1933 - val_acc: 0.9496 - val_auc: 0.9527 - val_loss: 0.5127 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - acc: 0.9481 - auc: 0.9519 - loss: 0.9307 - val_acc: 0.9499 - val_auc: 0.9532 - val_loss: 0.5021 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - acc: 0.9491 - auc: 0.9521 - loss: 0.7619 - val_acc: 0.9499 - val_auc: 0.9538 - val_loss: 0.4929 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - acc: 0.9476 - auc: 0.9527 - loss: 0.7765 - val_acc: 0.9492 - val_auc: 0.9542 - val_loss: 0.4861 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - acc: 0.9474 - auc: 0.9532 - loss: 0.7591 - val_acc: 0.9497 - val_auc: 0.9543 - val_loss: 0.4795 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - acc: 0.9480 - auc: 0.9548 - loss: 0.6395 - val_acc: 0.9499 - val_auc: 0.9546 - val_loss: 0.4731 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - acc: 0.9492 - auc: 0.9562 - loss: 0.6352 - val_acc: 0.9497 - val_auc: 0.9552 - val_loss: 0.4673 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - acc: 0.9491 - auc: 0.9550 - loss: 0.8469 - val_acc: 0.9499 - val_auc: 0.9550 - val_loss: 0.4622 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - acc: 0.9485 - auc: 0.9552 - loss: 0.6538 - val_acc: 0.9497 - val_auc: 0.9552 - val_loss: 0.4558 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - acc: 0.9478 - auc: 0.9570 - loss: 0.5695 - val_acc: 0.9492 - val_auc: 0.9557 - val_loss: 0.4509 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - acc: 0.9486 - auc: 0.9561 - loss: 0.6084 - val_acc: 0.9497 - val_auc: 0.9553 - val_loss: 0.4469 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - acc: 0.9486 - auc: 0.9577 - loss: 0.4140 - val_acc: 0.9469 - val_auc: 0.9562 - val_loss: 0.4447 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - acc: 0.9470 - auc: 0.9580 - loss: 0.7834 - val_acc: 0.9499 - val_auc: 0.9557 - val_loss: 0.4392 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - acc: 0.9501 - auc: 0.9579 - loss: 0.5865 - val_acc: 0.9486 - val_auc: 0.9563 - val_loss: 0.4332 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - acc: 0.9469 - auc: 0.9603 - loss: 0.4632 - val_acc: 0.9462 - val_auc: 0.9562 - val_loss: 0.4294 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - acc: 0.9485 - auc: 0.9594 - loss: 0.5441 - val_acc: 0.9499 - val_auc: 0.9558 - val_loss: 0.4251 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - acc: 0.9491 - auc: 0.9607 - loss: 0.5219 - val_acc: 0.9484 - val_auc: 0.9562 - val_loss: 0.4232 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - acc: 0.9492 - auc: 0.9604 - loss: 0.4846 - val_acc: 0.9496 - val_auc: 0.9557 - val_loss: 0.4187 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - acc: 0.9491 - auc: 0.9623 - loss: 0.7078 - val_acc: 0.9477 - val_auc: 0.9561 - val_loss: 0.4140 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - acc: 0.9486 - auc: 0.9616 - loss: 0.4881 - val_acc: 0.9489 - val_auc: 0.9558 - val_loss: 0.4089 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - acc: 0.9487 - auc: 0.9627 - loss: 0.4141 - val_acc: 0.9457 - val_auc: 0.9561 - val_loss: 0.4068 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - acc: 0.9489 - auc: 0.9619 - loss: 0.4181 - val_acc: 0.9497 - val_auc: 0.9548 - val_loss: 0.4055 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - acc: 0.9499 - auc: 0.9642 - loss: 0.4584 - val_acc: 0.9470 - val_auc: 0.9559 - val_loss: 0.4045 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - acc: 0.9495 - auc: 0.9631 - loss: 0.4471 - val_acc: 0.9469 - val_auc: 0.9556 - val_loss: 0.4010 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - acc: 0.9506 - auc: 0.9646 - loss: 0.4318 - val_acc: 0.9450 - val_auc: 0.9549 - val_loss: 0.3967 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - acc: 0.9493 - auc: 0.9649 - loss: 0.6360 - val_acc: 0.9460 - val_auc: 0.9558 - val_loss: 0.3927 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - acc: 0.9504 - auc: 0.9661 - loss: 0.4885 - val_acc: 0.9467 - val_auc: 0.9558 - val_loss: 0.3907 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - acc: 0.9515 - auc: 0.9654 - loss: 0.3627 - val_acc: 0.9460 - val_auc: 0.9550 - val_loss: 0.3876 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - acc: 0.9514 - auc: 0.9673 - loss: 0.3964 - val_acc: 0.9452 - val_auc: 0.9549 - val_loss: 0.3849 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - acc: 0.9507 - auc: 0.9672 - loss: 0.3785 - val_acc: 0.9426 - val_auc: 0.9545 - val_loss: 0.3840 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - acc: 0.9507 - auc: 0.9692 - loss: 0.2593 - val_acc: 0.9460 - val_auc: 0.9542 - val_loss: 0.3819 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - acc: 0.9527 - auc: 0.9692 - loss: 0.3108 - val_acc: 0.9428 - val_auc: 0.9537 - val_loss: 0.3807 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - acc: 0.9491 - auc: 0.9685 - loss: 0.3688 \n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - acc: 0.9503 - auc: 0.9689 - loss: 0.2944 - val_acc: 0.9435 - val_auc: 0.9537 - val_loss: 0.3806 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - acc: 0.9523 - auc: 0.9705 - loss: 0.3293 - val_acc: 0.9440 - val_auc: 0.9539 - val_loss: 0.3807 - learning_rate: 5.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - acc: 0.9520 - auc: 0.9701 - loss: 0.4216 - val_acc: 0.9448 - val_auc: 0.9547 - val_loss: 0.3822 - learning_rate: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "train_model(X_train_split, y_train_split, X_test_split, y_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b036965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1fa41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
